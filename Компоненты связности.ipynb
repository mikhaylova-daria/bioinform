{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#путь к данным\n",
    "path = './data/server3.lpm.org.ru/~baulin/mmCIF/out/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Получаем список нужных файлов и цепей из NR-списка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#достаем данные из NR-лист\n",
    "\n",
    "def get_files_chains(nr_list_file_name):\n",
    "    filter_data = open(nr_list_file_name)\n",
    "    filter_outfile = [] \n",
    "    \n",
    "    for i, line in enumerate(filter_data):\n",
    "        class_ = line.split('\\\",\\\"')[1].split('+')\n",
    "        filter_outfile += class_\n",
    "\n",
    "    filter_data.close()\n",
    "\n",
    "    files_chains = {}\n",
    "    for class_ in filter_outfile:\n",
    "        class_ = class_.split('|')\n",
    "        file_name = class_[0].lower() + '.out' + class_[1].strip()\n",
    "        try:\n",
    "            file = open(path + file_name)\n",
    "        except IOError as e:\n",
    "            continue\n",
    "        else:\n",
    "            with file:\n",
    "                if file_name not in files_chains:\n",
    "                    files_chains[file_name] = []\n",
    "                files_chains[file_name].append(class_[2])\n",
    "    return files_chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Строим набор компонент связности по файлу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stem_re  = r'List of (\\d+) stems'\n",
    "stack_re = r'List of (\\d+) stacks'\n",
    "neighbor_re = r'Summary of structural features of (\\d+) nucleotides'\n",
    "\n",
    "def get_matrix(data, chains):\n",
    "\n",
    "    #Достаем ребра из блока 'List of (\\d+) stems'\n",
    "    m_stem = re.search(stem_re, data)\n",
    "    data_stems = ''\n",
    "    stems = []\n",
    "    if m_stem is not None:\n",
    "        data_stems = data[m_stem.end():].split('****************************************************************************')[0]\n",
    "        stems = data_stems.split('--------------------------------------------------------------------------')\n",
    "    stems_output = []\n",
    "    for stem in stems:\n",
    "        stack1 = []\n",
    "        stack2 = []\n",
    "        for line in stem.split('\\n'):\n",
    "            line = line.split()\n",
    "            if len(line) > 0:\n",
    "                if line[0].isdigit():\n",
    "                    stack1.append(line[1])\n",
    "                    stack2.append(line[2])\n",
    "        for i in range(len(stack1)-1):\n",
    "            stems_output.append({'edge':(stack1[i], stack1[i+1]), 'type':'stem'} )\n",
    "        for i in range(len(stack2)-1):\n",
    "            stems_output.append({'edge':(stack2[i], stack2[i+1]), 'type':'stem'})\n",
    "\n",
    "\n",
    "    #Достаем ребра из блока 'List of (\\d+) stacks'\n",
    "    m_stack = re.search(stack_re, data)\n",
    "    data_stacks=''\n",
    "    if m_stack is not None:\n",
    "        data_stacks = data[m_stack.end():].split('****************************************************************************')[0]\n",
    "    stacks_output = []\n",
    "    for stack in data_stacks.split('\\n'):\n",
    "        stack = stack.strip().split()\n",
    "        if len(stack)>0:\n",
    "            if stack[0].isdigit():\n",
    "                stack = stack[3].split(',')\n",
    "                for i in range(len(stack)-1):\n",
    "                    stacks_output.append({'edge':(stack[i], stack[i+1]), 'type':'stack'} )\n",
    "\n",
    "\n",
    "    #Достаем ребра из блока 'Summary of structural features of (\\d+) nucleotides'\n",
    "    m_neighbor = re.search(neighbor_re, data) \n",
    "    data_neighbors=''\n",
    "    if m_neighbor is not None:\n",
    "        data_neighbors = data[m_neighbor.end():].split('****************************************************************************')[0]\n",
    "    neighbor_output = []\n",
    "    last_item = None\n",
    "    for stack in data_neighbors.split('\\n'):\n",
    "        stack = stack.strip().split()\n",
    "        if len(stack)>0:\n",
    "            if stack[0].isdigit():\n",
    "                if last_item is None:\n",
    "                    last_item = stack[3]\n",
    "                else:\n",
    "                    if last_item.split('.')[:-3]==stack[3].split('.')[:-3]:\n",
    "                        neighbor_output.append({'edge':( last_item, stack[3]), 'type':'neighbor'} )\n",
    "                        last_item = stack[3]\n",
    "                    else:\n",
    "                        last_item = stack[3]\n",
    "\n",
    "\n",
    "    #Все ребра между нуклеотидами (без связей внутри А-минора)\n",
    "    edges = stacks_output+stems_output + neighbor_output\n",
    "\n",
    "\n",
    "    #Достаем А-миноры 'List of (\\d+) A-minor motifs'\n",
    "    a_minor_re = r'List of (\\d+) A-minor motifs'\n",
    "    m_a_minor = re.search(a_minor_re, data) \n",
    "    a_minor_data=''\n",
    "    \n",
    "    if m_a_minor is not None:\n",
    "        a_minor_data = data[m_a_minor.end():].split('****************************************************************************')[0]\n",
    "\n",
    "            \n",
    "            \n",
    "#собираем граф        \n",
    "\n",
    "    a_minors = {}\n",
    "    a_minor_vert = set()\n",
    "    last_item = None\n",
    "    for stack in a_minor_data.split('\\n'):\n",
    "        stack = stack.strip().split()\n",
    "        if len(stack)>0:\n",
    "            if stack[0].isdigit():\n",
    "                if stack[3].split('.')[2] in chains:\n",
    "                    a_minor_vert.add(stack[3])\n",
    "                f_stack, mid_stack = stack[3].split('|')\n",
    "                s_stack, th_stack  = mid_stack.split(',')\n",
    "                if f_stack not in a_minors:\n",
    "                    a_minors[f_stack] = []\n",
    "                a_minors[f_stack].append(stack[3])\n",
    "                if s_stack not in a_minors:\n",
    "                    a_minors[s_stack] = []\n",
    "                a_minors[s_stack].append(stack[3])\n",
    "                if th_stack not in a_minors:\n",
    "                    a_minors[th_stack] = []\n",
    "                a_minors[th_stack].append(stack[3])\n",
    "\n",
    "    #Матрица смежности А-миноров\n",
    "\n",
    "    matrix = {}\n",
    "    matrix_type = {}\n",
    "    for i, x in enumerate(a_minor_vert):\n",
    "        matrix[x]={}\n",
    "        matrix_type[x] = {}\n",
    "        for y in a_minor_vert:\n",
    "            if x<y:\n",
    "                matrix[x][y]=[]\n",
    "                matrix_type[x][y]=[]\n",
    "                \n",
    "\n",
    "    edges = stacks_output+stems_output + neighbor_output \n",
    "\n",
    "\n",
    "    for e in edges:\n",
    "        a, b = min(e['edge']), max(e['edge'])\n",
    "        if a in a_minors and b in a_minors:\n",
    "            for x in a_minors[a]:\n",
    "                if x in a_minor_vert:\n",
    "                    for y in a_minors[b]:\n",
    "                        if y in a_minor_vert:\n",
    "                            if x < y:\n",
    "                                matrix[x][y].append(e['type']+'_'+a+'_'+b)\n",
    "                            if x > y:\n",
    "                                matrix[y][x].append(e['type']+'_'+a+'_'+b)\n",
    "\n",
    "\n",
    "    for x in matrix:\n",
    "        matrix[x][x]=[]                                \n",
    "                                \n",
    "#связь между А-минорами по общим нуклеотидам\n",
    "    for c in a_minors:\n",
    "        if len(a_minors[c])>1:\n",
    "            for i in range(len(a_minors[c])):\n",
    "                if a_minors[c][i] in a_minor_vert:\n",
    "                    for j in range(len(a_minors[c])):\n",
    "                        if a_minors[c][j] in a_minor_vert:\n",
    "                            if a_minors[c][i]<a_minors[c][j]:\n",
    "                                matrix[a_minors[c][i]][a_minors[c][j]].append('a_minor_'+c)\n",
    "                            else: \n",
    "                                matrix[a_minors[c][j]][a_minors[c][i]].append('a_minor_'+c)\n",
    "\n",
    "    for x in matrix:\n",
    "        for y in matrix:\n",
    "            if x < y:\n",
    "                matrix[y][x]=matrix[x][y]            \n",
    "        matrix[x][x]=[]\n",
    "    \n",
    "    for x in matrix:\n",
    "        for y in matrix:\n",
    "            for t in matrix[x][y]:\n",
    "                if t.find('a_minor_')!= -1:\n",
    "                    matrix[y][x] = []\n",
    "                    matrix[x][y] = []\n",
    "    \n",
    "    \n",
    "    for x in matrix_type:\n",
    "        for y in matrix_type:\n",
    "            if x<y:\n",
    "                eat = {}\n",
    "                for e in matrix[x][y]:\n",
    "                    et, e1, e2 = e.split('_')\n",
    "                    ax, nnx = x.split('|')\n",
    "                    lnx, rnx  = nnx.split(',')\n",
    "                    ay, nny = y.split('|')\n",
    "                    lny, rny  = nny.split(',')\n",
    "\n",
    "                    type_str = ''\n",
    "                    if lnx in (e1, e2):\n",
    "                        type_str += 'L'\n",
    "                    elif rnx in (e1, e2):\n",
    "                        type_str += 'R'\n",
    "                    elif ax in (e1, e2):\n",
    "                        type_str += 'A'\n",
    "                    if lny in (e1, e2):\n",
    "                        type_str += 'L'\n",
    "                    elif rny in (e1, e2):\n",
    "                        type_str += 'R'\n",
    "                    elif ay in (e1, e2):\n",
    "                        type_str += 'A'\n",
    "\n",
    "                    if type_str not in eat:\n",
    "                        eat[type_str] = []\n",
    "                    eat[type_str].append(et[0])\n",
    "                    eat[type_str].sort()\n",
    "                for e in eat:\n",
    "                    new_t = ''.join(eat[e])+e\n",
    "                    if x<y and new_t not in matrix_type[x][y]:\n",
    "                        matrix_type[x][y].append(new_t)\n",
    "                        matrix_type[x][y].sort()\n",
    "                    if y<x:\n",
    "                        matrix_type[y][x].append(new_t)\n",
    "                        matrix_type[y][x].sort()\n",
    "                        \n",
    "                        \n",
    "    #заполняем симметрично с учетом того, что изменилось \"направление\" ребер \n",
    "    for x in matrix_type:\n",
    "        for y in matrix_type:\n",
    "            if x < y:\n",
    "                matrix_type[y][x]=[item[:-2]+item[-1]+ item[-2] for item in matrix_type[x][y]]\n",
    "        matrix_type[x][x]=[]\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    return matrix, matrix_type, len(a_minor_vert)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Связность компонент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#наличие цикла в данной компоненте\n",
    "has_cycle = 0\n",
    "#порядок обхода\n",
    "order = 0\n",
    "\n",
    "def sub_dfs(u, matrix, visited, component):\n",
    "    global has_cycle\n",
    "    global order\n",
    "    visited[u][0] = 1\n",
    "    visited[u][2] = order\n",
    "    order += 1\n",
    "    numerator = {}\n",
    "    \n",
    "    for v in matrix[u]:\n",
    "        if len(matrix[u][v])>0:\n",
    "            a, b = min((u, v)), max((u, v))\n",
    "            if {'edge': (a, b), 'links': matrix[a][b], 'edge_pattern':visited[a][1] + '_'+visited[b][1]} not in component:\n",
    "                if visited[v][0] == 1:\n",
    "                    has_cycle+=1\n",
    "                component.append({'edge': (a, b), 'links': matrix[a][b], 'edge_pattern': visited[a][1] + '_'+visited[b][1]})\n",
    "            if visited[v][0] == 0:\n",
    "                sub_dfs(v, matrix, visited, component)\n",
    "    visited[u][0] = 2\n",
    "    \n",
    "\n",
    "def dfs(matrix):\n",
    "    global has_cycle\n",
    "    global order\n",
    "    text=[]\n",
    "    cycle_text = []\n",
    "    line_components = []\n",
    "    cycle_components = []\n",
    "    triv_components =[]\n",
    "    visited = {ver:[0, 'v'+str(i), 0] for i, ver in enumerate(matrix)}\n",
    "    component = []\n",
    "    for v in matrix:            \n",
    "        if not visited[v][0]:\n",
    "            component = []\n",
    "            has_cycle = 0\n",
    "            sub_dfs(v, matrix, visited, component)\n",
    "            if has_cycle > 0:\n",
    "                cycle_components.append(component)\n",
    "            elif len(component)>0:\n",
    "                line_components.append(component)\n",
    "            if len(component) == 0:\n",
    "                triv_components.append(v)\n",
    "            \n",
    "    order = 0\n",
    "    has_cycle = 0\n",
    "    return  cycle_components, line_components, triv_components\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вытаскиваем ветки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line(comp):\n",
    "    matrix = {}\n",
    "    number_vert={}\n",
    "    for i, e in enumerate(comp):\n",
    "        v1, v2 = e['edge_pattern'].split('_')\n",
    "        \n",
    "        if v1 not in number_vert:\n",
    "            number_vert[v1]=0\n",
    "        number_vert[v1]+=1\n",
    "        if v2 not in number_vert:\n",
    "            number_vert[v2]=0\n",
    "        number_vert[v2]+=1\n",
    "        if v1 not in matrix:\n",
    "            matrix[v1]={}\n",
    "        if v2 not in matrix:\n",
    "            matrix[v2]={}\n",
    "        matrix[v1][v2] = [1]\n",
    "        matrix[v2][v1] = [1]\n",
    "    visited = {ver:[0, ver, 0] for i, ver in enumerate(matrix)}\n",
    "    for v in number_vert:\n",
    "        if number_vert[v]==1:\n",
    "            if visited[v][0]==0:\n",
    "                component = []\n",
    "                sub_dfs(v, matrix, visited, component)\n",
    "                for x in comp:\n",
    "                    for i, y in enumerate(component):\n",
    "                        x1, x2 = x['edge_pattern'].split('_')\n",
    "                        y1, y2 = y['edge_pattern'].split('_')\n",
    "                        #if visited[min(x1, x2)] > visited[max(x1, x2)]\n",
    "                            \n",
    "                \n",
    "                        if min(x1, x2)==min(y1, y2) and max(x1, x2)==max(y1, y2):\n",
    "                            #component[i]['edge']=\n",
    "                            component[i]['edge']=x['edge']\n",
    "                            component[i]['links']=x['links']\n",
    "                            component[i]['type_pattern']=x['type_pattern']\n",
    "                return component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "\n",
    "def make_files_with_components(result_path, nr_list_name):\n",
    "    files_chains = get_files_chains(nr_list_name)\n",
    "\n",
    "    directory = os.path.dirname(result_path)\n",
    "\n",
    "    path_triv = result_path + 'triv' + os.sep\n",
    "    path_line = result_path + 'line' + os.sep\n",
    "    path_cycle = result_path + 'cycle' + os.sep\n",
    "    all_cycle_components = []\n",
    "    all_line_components = []\n",
    "    all_triv_components = []\n",
    "\n",
    "    try:\n",
    "        os.stat(directory)\n",
    "    except:\n",
    "        os.mkdir(directory)   \n",
    "\n",
    "    try:\n",
    "        os.stat(os.path.dirname(path_triv))\n",
    "    except:\n",
    "        os.mkdir(os.path.dirname(path_triv))    \n",
    "\n",
    "    try:\n",
    "        os.stat(os.path.dirname(path_line))\n",
    "    except:\n",
    "        os.mkdir(os.path.dirname(path_line))   \n",
    "\n",
    "    try:\n",
    "        os.stat(os.path.dirname(path_cycle))\n",
    "    except:\n",
    "        os.mkdir(os.path.dirname(path_cycle)) \n",
    "\n",
    "\n",
    "    count_all = 0\n",
    "    count_cycle = 0\n",
    "    count_a_minor = 0\n",
    "    count_line = 0\n",
    "    f = open(result_path + 'unusual_line', 'w')\n",
    "    type_patterns_in_simple_line=[]\n",
    "    type_patterns_in_cycle=[]\n",
    "    triv_components = []\n",
    "\n",
    "    for i, x in enumerate(files_chains):\n",
    "\n",
    "        text = []\n",
    "        cycle_text = []\n",
    "        line_text = []\n",
    "\n",
    "        my_matrix = get_matrix(open(path + x).read(), files_chains[x])\n",
    "        cycle_components, line_components, triv_components = dfs(my_matrix[0])                \n",
    "        count_a_minor += my_matrix[2]\n",
    "        for c in cycle_components:\n",
    "            all_cycle_components.append(c)\n",
    "            for i, e in enumerate(c):\n",
    "                e['type_pattern'] = [t for t in set(my_matrix[1][e['edge'][0]][e['edge'][1]])]\n",
    "                type_patterns_in_cycle.append(e['type_pattern'])\n",
    "                c[i]=e\n",
    "            cycle_text.append(str(c))\n",
    "        for c in line_components:\n",
    "            all_line_components.append(c)\n",
    "            for i, e in enumerate(c):\n",
    "                e['type_pattern'] = [t for t in set(my_matrix[1][e['edge'][0]][e['edge'][1]])]\n",
    "                c[i]=e\n",
    "                type_patterns_in_simple_line.append(e['type_pattern'] )\n",
    "                for t in e['type_pattern']:\n",
    "                    if t[-1]!=t[-2]:\n",
    "                        f.write(str(e['type_pattern']) + '\\t' + x.split('.')[0] + '_line\\n')\n",
    "            line_text.append(str(get_line(c)))\n",
    "        if len(cycle_components)>0:\n",
    "            count_cycle += len(cycle_components)\n",
    "            f_comp = open(path_cycle + x.split('.')[0] + '_cycle', 'w')\n",
    "            f_comp.write('\\n'.join(cycle_text))\n",
    "            f_comp.close()\n",
    "        if len(line_components)>0:\n",
    "            count_line += len(line_components)\n",
    "            f_comp = open(path_line + x.split('.')[0] + '_line', 'w')\n",
    "            f_comp.write('\\n'.join(line_text))\n",
    "            f_comp.close()\n",
    "        if len(triv_components)>0:\n",
    "            all_triv_components.append(c)\n",
    "            f_comp = open(path_triv +x.split('.')[0] + '_triv', 'w')\n",
    "            f_comp.write('\\n'.join(triv_components))\n",
    "            f_comp.close()\n",
    "    f.close()\n",
    "    return all_cycle_components, all_line_components, all_triv_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Получаем типы компонент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c -- компонента, возвращаем (число а-миноров, число аденинов, число спариваний)\n",
    "def get_type(c):\n",
    "    ver = set()\n",
    "    for e in c:\n",
    "        ver.add(e['edge'][0])\n",
    "        ver.add(e['edge'][1])\n",
    "    ad = set()\n",
    "    pr = set()\n",
    "    for v in ver:\n",
    "        a, p = v.split('|')\n",
    "        ad.add(a)\n",
    "        pr.add(p)\n",
    "    return  len(ver), len(ad), len(pr)\n",
    "\n",
    "def get_count(cs):\n",
    "    ver = set()\n",
    "    ad = set()\n",
    "    pr = set()\n",
    "    for c in cs:\n",
    "        for e in c:\n",
    "            ver.add(e['edge'][0])\n",
    "            ver.add(e['edge'][1])\n",
    "\n",
    "        for v in ver:\n",
    "            a, p = v.split('|')\n",
    "            ad.add(a)\n",
    "            pr.add(p)\n",
    "    return  len(ver), len(ad), len(pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка NR-файлов и генерация файлов с компонентами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def print_stat(comps, text):\n",
    "    types= []\n",
    "    print text\n",
    "    for c in comps:\n",
    "        types.append(get_type(c))\n",
    "    counter_types = collections.Counter(types)\n",
    "    print counter_types\n",
    "    print 'Кол-во а-миноров, кол-во аденинов, кол-во спариваний, кол-во представителей типа'\n",
    "    for i in counter_types.most_common(len(counter_types)):\n",
    "        print i\n",
    "        \n",
    "    count = get_count(comps)\n",
    "    print 'всего а-миноров: ', count[0]\n",
    "    print 'всего аденинов: ', count[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def collect_types(result_path, comps):\n",
    "    \n",
    "    path_line = result_path  + os.sep + 'line' + os.sep\n",
    "    path_cycle = result_path  + os.sep + 'cycle' + os.sep\n",
    "    path_all = result_path  + os.sep + 'all' + os.sep\n",
    "    path_all_simple_format = result_path  + os.sep + 'all_simple_format' + os.sep\n",
    "\n",
    "    try:\n",
    "        os.stat(os.path.dirname(result_path))\n",
    "    except:\n",
    "        os.mkdir(os.path.dirname(result_path))   \n",
    "\n",
    "    try:\n",
    "        os.stat(os.path.dirname(path_line))\n",
    "    except:\n",
    "        os.mkdir(os.path.dirname(path_line))   \n",
    "\n",
    "    try:\n",
    "        os.stat(os.path.dirname(path_cycle))\n",
    "    except:\n",
    "        os.mkdir(os.path.dirname(path_cycle)) \n",
    "        \n",
    "        \n",
    "    try:\n",
    "        os.stat(os.path.dirname(path_all))\n",
    "    except:\n",
    "        os.mkdir(os.path.dirname(path_all)) \n",
    "        \n",
    "    try:\n",
    "        os.stat(os.path.dirname(path_all_simple_format))\n",
    "    except:\n",
    "        os.mkdir(os.path.dirname(path_all_simple_format)) \n",
    "        \n",
    "    types = {}\n",
    "    \n",
    "    for c in comps[1]:\n",
    "        t = get_type(c)\n",
    "        if t not in types:\n",
    "            types[t] = []\n",
    "        types[t].append(c)\n",
    "    for t in types:\n",
    "        with open(path_line+str(t), 'w') as fp:\n",
    "            json.dump(types[t], fp)\n",
    "    \n",
    "    types = {}\n",
    "    for c in comps[0]:\n",
    "        t = get_type(c)\n",
    "        if t not in types:\n",
    "            types[t] = []\n",
    "        types[t].append(c)\n",
    "    for t in types:\n",
    "        with open(path_cycle+str(t), 'w') as fp:\n",
    "            json.dump(types[t], fp)\n",
    "                   \n",
    "         \n",
    "    types = {}\n",
    "    \n",
    "    for c in comps[0] + comps[1]:\n",
    "        t = get_type(c)\n",
    "        if t not in types:\n",
    "            types[t] = []\n",
    "        types[t].append(c)\n",
    "    for t in types:\n",
    "        with open(path_all+str(t), 'w') as fp:\n",
    "            json.dump(types[t], fp)\n",
    "    for t in types:\n",
    "        with open(path_all_simple_format+str(t), 'w') as fp:\n",
    "            for c in types[t]:\n",
    "                fp.write('—————————————————\\npdbfile\\nvertices\\n')\n",
    "                for x in c:\n",
    "                    fp.write(x[\"edge_pattern\"].split('_')[0] + '\\t'+ x[\"edge\"][0] + '\\n')\n",
    "                    fp.write(x[\"edge_pattern\"].split('_')[1] + '\\t'+ x[\"edge\"][1] + '\\n')\n",
    "                fp.write('\\nedges\\n')\n",
    "                for x in c:\n",
    "                    fp.write(x[\"edge_pattern\"].split('_')[0] + '\\t'+x[\"edge_pattern\"].split('_')[1] + '\\t'+ str(x[\"type_pattern\"]) + '\\n')\n",
    "                fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_nr_35a = make_files_with_components('./result_nr_list_nrlist_3.36_3.5A/', './data/nrlist_3.36_3.5A.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrlist_3.36_3.5A:\n",
      "\tЦиклов:  59 \n",
      "\tВеток:  830 \n",
      "\tТривиальных компонент:  145\n"
     ]
    }
   ],
   "source": [
    "print 'nrlist_3.36_3.5A:'\n",
    "\n",
    "print '\\tЦиклов: ', len(components_nr_35a[0]),\\\n",
    "      '\\n\\tВеток: ', len(components_nr_35a[1]),\\\n",
    "      '\\n\\tТривиальных компонент: ', len(components_nr_35a[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrlist_3.36_3.5A: Циклы\n",
      "Counter({(4, 4, 3): 14, (5, 4, 3): 13, (3, 3, 3): 3, (6, 4, 3): 3, (6, 6, 5): 3, (6, 5, 4): 3, (6, 6, 4): 3, (4, 4, 2): 3, (5, 5, 3): 2, (5, 5, 4): 2, (5, 4, 4): 2, (8, 7, 5): 1, (7, 6, 5): 1, (7, 6, 6): 1, (7, 7, 5): 1, (7, 5, 4): 1, (6, 5, 3): 1, (5, 4, 2): 1, (9, 9, 8): 1})\n",
      "Кол-во а-миноров, кол-во аденинов, кол-во спариваний, кол-во представителей типа\n",
      "((4, 4, 3), 14)\n",
      "((5, 4, 3), 13)\n",
      "((3, 3, 3), 3)\n",
      "((6, 4, 3), 3)\n",
      "((6, 6, 5), 3)\n",
      "((6, 5, 4), 3)\n",
      "((6, 6, 4), 3)\n",
      "((4, 4, 2), 3)\n",
      "((5, 5, 3), 2)\n",
      "((5, 5, 4), 2)\n",
      "((5, 4, 4), 2)\n",
      "((8, 7, 5), 1)\n",
      "((7, 6, 5), 1)\n",
      "((7, 6, 6), 1)\n",
      "((7, 7, 5), 1)\n",
      "((7, 5, 4), 1)\n",
      "((6, 5, 3), 1)\n",
      "((5, 4, 2), 1)\n",
      "((9, 9, 8), 1)\n",
      "всего а-миноров:  300\n",
      "всего аденинов:  260\n",
      "\n",
      "\n",
      "nrlist_3.36_3.5A: Ветки\n",
      "Counter({(2, 2, 2): 546, (3, 3, 3): 89, (3, 3, 2): 74, (4, 4, 4): 39, (4, 3, 2): 16, (5, 5, 5): 12, (6, 5, 6): 10, (4, 4, 3): 8, (5, 5, 4): 6, (4, 3, 3): 4, (7, 6, 6): 3, (3, 2, 3): 3, (5, 4, 4): 3, (4, 4, 2): 3, (8, 7, 7): 2, (6, 6, 6): 2, (7, 7, 7): 2, (8, 8, 7): 1, (6, 5, 4): 1, (6, 5, 5): 1, (5, 5, 3): 1, (7, 5, 6): 1, (5, 4, 5): 1, (5, 3, 5): 1, (4, 2, 3): 1})\n",
      "Кол-во а-миноров, кол-во аденинов, кол-во спариваний, кол-во представителей типа\n",
      "((2, 2, 2), 546)\n",
      "((3, 3, 3), 89)\n",
      "((3, 3, 2), 74)\n",
      "((4, 4, 4), 39)\n",
      "((4, 3, 2), 16)\n",
      "((5, 5, 5), 12)\n",
      "((6, 5, 6), 10)\n",
      "((4, 4, 3), 8)\n",
      "((5, 5, 4), 6)\n",
      "((4, 3, 3), 4)\n",
      "((7, 6, 6), 3)\n",
      "((3, 2, 3), 3)\n",
      "((5, 4, 4), 3)\n",
      "((4, 4, 2), 3)\n",
      "((8, 7, 7), 2)\n",
      "((6, 6, 6), 2)\n",
      "((7, 7, 7), 2)\n",
      "((8, 8, 7), 1)\n",
      "((6, 5, 4), 1)\n",
      "((6, 5, 5), 1)\n",
      "((5, 5, 3), 1)\n",
      "((7, 5, 6), 1)\n",
      "((5, 4, 5), 1)\n",
      "((5, 3, 5), 1)\n",
      "((4, 2, 3), 1)\n",
      "всего а-миноров:  2083\n",
      "всего аденинов:  1943\n"
     ]
    }
   ],
   "source": [
    "print_stat(components_nr_35a[0], 'nrlist_3.36_3.5A: Циклы')\n",
    "print '\\n'\n",
    "print_stat(components_nr_35a[1], 'nrlist_3.36_3.5A: Ветки')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_types('./data_35a', components_nr_35a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrlist_3.36_3.5A: Суммарно\n",
      "Counter({(2, 2, 2): 546, (3, 3, 3): 92, (3, 3, 2): 74, (4, 4, 4): 39, (4, 4, 3): 22, (4, 3, 2): 16, (5, 4, 3): 13, (5, 5, 5): 12, (6, 5, 6): 10, (5, 5, 4): 8, (4, 4, 2): 6, (5, 4, 4): 5, (7, 6, 6): 4, (4, 3, 3): 4, (6, 5, 4): 4, (5, 5, 3): 3, (6, 4, 3): 3, (3, 2, 3): 3, (6, 6, 5): 3, (6, 6, 4): 3, (8, 7, 7): 2, (7, 7, 7): 2, (6, 6, 6): 2, (7, 6, 5): 1, (8, 7, 5): 1, (8, 8, 7): 1, (5, 4, 2): 1, (9, 9, 8): 1, (6, 5, 5): 1, (6, 5, 3): 1, (7, 5, 6): 1, (5, 4, 5): 1, (7, 7, 5): 1, (7, 5, 4): 1, (4, 2, 3): 1, (5, 3, 5): 1})\n",
      "Кол-во а-миноров, кол-во аденинов, кол-во спариваний, кол-во представителей типа\n",
      "((2, 2, 2), 546)\n",
      "((3, 3, 3), 92)\n",
      "((3, 3, 2), 74)\n",
      "((4, 4, 4), 39)\n",
      "((4, 4, 3), 22)\n",
      "((4, 3, 2), 16)\n",
      "((5, 4, 3), 13)\n",
      "((5, 5, 5), 12)\n",
      "((6, 5, 6), 10)\n",
      "((5, 5, 4), 8)\n",
      "((4, 4, 2), 6)\n",
      "((5, 4, 4), 5)\n",
      "((7, 6, 6), 4)\n",
      "((4, 3, 3), 4)\n",
      "((6, 5, 4), 4)\n",
      "((5, 5, 3), 3)\n",
      "((6, 4, 3), 3)\n",
      "((3, 2, 3), 3)\n",
      "((6, 6, 5), 3)\n",
      "((6, 6, 4), 3)\n",
      "((8, 7, 7), 2)\n",
      "((7, 7, 7), 2)\n",
      "((6, 6, 6), 2)\n",
      "((7, 6, 5), 1)\n",
      "((8, 7, 5), 1)\n",
      "((8, 8, 7), 1)\n",
      "((5, 4, 2), 1)\n",
      "((9, 9, 8), 1)\n",
      "((6, 5, 5), 1)\n",
      "((6, 5, 3), 1)\n",
      "((7, 5, 6), 1)\n",
      "((5, 4, 5), 1)\n",
      "((7, 7, 5), 1)\n",
      "((7, 5, 4), 1)\n",
      "((4, 2, 3), 1)\n",
      "((5, 3, 5), 1)\n",
      "всего а-миноров:  2379\n",
      "всего аденинов:  2162\n"
     ]
    }
   ],
   "source": [
    "print_stat(components_nr_35a[0]+components_nr_35a[1], 'nrlist_3.36_3.5A: Суммарно')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
